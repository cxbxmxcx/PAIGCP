{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAIGCP_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOon4bJkMZBRt5LS/ijtFKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cxbxmxcx/PAIGCP/blob/master/PAIGCP_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhUrDc_zOA-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG0JNbJsRfwT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "090686f1-6f70-4c1f-d1df-c7848cdc2557"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
        "path_to_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EswXJREBNYY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "bdd86aaf-37de-4fee-a859-321609de9e7c"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(path_to_file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "lines[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Go.\\tVe.',\n",
              " 'Go.\\tVete.',\n",
              " 'Go.\\tVaya.',\n",
              " 'Go.\\tVáyase.',\n",
              " 'Hi.\\tHola.',\n",
              " 'Run!\\t¡Corre!',\n",
              " 'Run.\\tCorred.',\n",
              " 'Who?\\t¿Quién?',\n",
              " 'Fire!\\t¡Fuego!',\n",
              " 'Fire!\\t¡Incendio!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFmWesFKR6pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples = 1000\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeeqI8GCSO8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "51f9dcb8-8f6d-41e7-81cc-0d5feca621fe"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_encoder_tokens, \",\".join(input_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61,\n",
              " \" ,!,',,,.,0,1,3,8,9,:,?,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,R,S,T,U,V,W,Y,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKsMQLeaSajS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "11922cd1-a0ca-452c-9ac7-7e40ed604d42"
      },
      "source": [
        "target_characters = sorted(list(target_characters))\n",
        "num_decoder_tokens = len(target_characters)\n",
        "num_decoder_tokens, \",\".join(target_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70,\n",
              " '\\t,\\n, ,!,,,.,0,3,8,:,?,A,B,C,D,E,F,G,H,I,J,L,M,N,O,P,Q,R,S,T,U,V,Y,a,b,c,d,e,f,g,h,i,j,l,m,n,o,p,q,r,s,t,u,v,x,y,z,¡,¿,Á,É,Ó,Ú,á,é,í,ñ,ó,ú,ü')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfuLaoVUD2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "746f953a-c606-4ff2-82a0-e6369fe23a40"
      },
      "source": [
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length for inputs: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwdHoAo41sx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49084ed2-5d75-456f-c39b-1085398217a2"
      },
      "source": [
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length for outputs: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHc1qMwjVCQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UgjBMmhVZU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNJTVSHO3NQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Reshape\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 64  # Latent dimensionality of the encoding space.\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "#encoder_embedded = Embedding(input_dim=num_encoder_tokens, output_dim=64)(encoder_inputs)\n",
        "#encoder_reshape = Reshape((-1, 64))(encoder_embedded)\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za7_kDtc4Gax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkuLHwekRO2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ceab26-609c-4286-c015-e6d03733e8fa"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 100\n",
        "encoder_input_data.shape,decoder_input_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 11, 61), (1000, 31, 70))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-iU3cxY4qiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e7dabe1-b899-4951-eba5-3b402f8f54f9"
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 3.3758 - accuracy: 0.5017 - val_loss: 2.1734 - val_accuracy: 0.5777\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.7953 - accuracy: 0.6275 - val_loss: 1.9087 - val_accuracy: 0.5744\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.6027 - accuracy: 0.6265 - val_loss: 1.7623 - val_accuracy: 0.5731\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.5276 - accuracy: 0.6279 - val_loss: 1.7184 - val_accuracy: 0.5808\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.4907 - accuracy: 0.6279 - val_loss: 1.6831 - val_accuracy: 0.5787\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.4550 - accuracy: 0.6304 - val_loss: 1.7033 - val_accuracy: 0.5885\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.4257 - accuracy: 0.6348 - val_loss: 1.6383 - val_accuracy: 0.5852\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.4009 - accuracy: 0.6354 - val_loss: 1.6056 - val_accuracy: 0.5852\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.3657 - accuracy: 0.6364 - val_loss: 1.5636 - val_accuracy: 0.5818\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.3541 - accuracy: 0.6381 - val_loss: 1.5429 - val_accuracy: 0.5874\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.3300 - accuracy: 0.6407 - val_loss: 1.5173 - val_accuracy: 0.5894\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.3094 - accuracy: 0.6447 - val_loss: 1.5152 - val_accuracy: 0.5902\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 1.2850 - accuracy: 0.6465 - val_loss: 1.5090 - val_accuracy: 0.5900\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.2668 - accuracy: 0.6517 - val_loss: 1.4856 - val_accuracy: 0.5927\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.2545 - accuracy: 0.6569 - val_loss: 1.4439 - val_accuracy: 0.5956\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.2277 - accuracy: 0.6612 - val_loss: 1.4186 - val_accuracy: 0.6074\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.2127 - accuracy: 0.6692 - val_loss: 1.4098 - val_accuracy: 0.6161\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.2023 - accuracy: 0.6785 - val_loss: 1.3878 - val_accuracy: 0.6355\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.1801 - accuracy: 0.6871 - val_loss: 1.3800 - val_accuracy: 0.6265\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.1642 - accuracy: 0.6931 - val_loss: 1.4433 - val_accuracy: 0.6026\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.1519 - accuracy: 0.6966 - val_loss: 1.3476 - val_accuracy: 0.6387\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.1384 - accuracy: 0.7000 - val_loss: 1.3278 - val_accuracy: 0.6463\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.1191 - accuracy: 0.7078 - val_loss: 1.3109 - val_accuracy: 0.6473\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.1111 - accuracy: 0.7101 - val_loss: 1.3061 - val_accuracy: 0.6489\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.0920 - accuracy: 0.7144 - val_loss: 1.3037 - val_accuracy: 0.6453\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.0803 - accuracy: 0.7178 - val_loss: 1.2765 - val_accuracy: 0.6565\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.0676 - accuracy: 0.7210 - val_loss: 1.2781 - val_accuracy: 0.6492\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.0515 - accuracy: 0.7256 - val_loss: 1.2460 - val_accuracy: 0.6752\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.0453 - accuracy: 0.7257 - val_loss: 1.2347 - val_accuracy: 0.6669\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.0265 - accuracy: 0.7293 - val_loss: 1.2283 - val_accuracy: 0.6694\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.0154 - accuracy: 0.7310 - val_loss: 1.2207 - val_accuracy: 0.6703\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.0018 - accuracy: 0.7335 - val_loss: 1.2072 - val_accuracy: 0.6668\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9917 - accuracy: 0.7342 - val_loss: 1.1838 - val_accuracy: 0.6798\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9774 - accuracy: 0.7361 - val_loss: 1.1854 - val_accuracy: 0.6868\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9643 - accuracy: 0.7400 - val_loss: 1.1625 - val_accuracy: 0.6831\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9541 - accuracy: 0.7401 - val_loss: 1.1549 - val_accuracy: 0.6840\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9413 - accuracy: 0.7429 - val_loss: 1.1386 - val_accuracy: 0.6834\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9296 - accuracy: 0.7438 - val_loss: 1.1314 - val_accuracy: 0.6853\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9170 - accuracy: 0.7471 - val_loss: 1.1208 - val_accuracy: 0.6916\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9081 - accuracy: 0.7498 - val_loss: 1.1234 - val_accuracy: 0.6781\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8963 - accuracy: 0.7528 - val_loss: 1.1042 - val_accuracy: 0.6890\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8853 - accuracy: 0.7545 - val_loss: 1.0868 - val_accuracy: 0.6902\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8759 - accuracy: 0.7552 - val_loss: 1.0849 - val_accuracy: 0.6877\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8669 - accuracy: 0.7563 - val_loss: 1.0749 - val_accuracy: 0.6848\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8584 - accuracy: 0.7600 - val_loss: 1.0624 - val_accuracy: 0.6918\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8450 - accuracy: 0.7616 - val_loss: 1.0523 - val_accuracy: 0.6911\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8404 - accuracy: 0.7620 - val_loss: 1.0539 - val_accuracy: 0.6927\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8294 - accuracy: 0.7647 - val_loss: 1.0419 - val_accuracy: 0.6927\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8254 - accuracy: 0.7623 - val_loss: 1.0392 - val_accuracy: 0.6990\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8145 - accuracy: 0.7666 - val_loss: 1.0302 - val_accuracy: 0.6989\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8102 - accuracy: 0.7665 - val_loss: 1.0235 - val_accuracy: 0.6977\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8019 - accuracy: 0.7703 - val_loss: 1.0170 - val_accuracy: 0.7010\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7937 - accuracy: 0.7730 - val_loss: 1.0248 - val_accuracy: 0.6944\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7881 - accuracy: 0.7750 - val_loss: 1.0192 - val_accuracy: 0.6953\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7839 - accuracy: 0.7730 - val_loss: 0.9980 - val_accuracy: 0.7066\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7752 - accuracy: 0.7784 - val_loss: 1.0022 - val_accuracy: 0.7092\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.7712 - accuracy: 0.7788 - val_loss: 0.9954 - val_accuracy: 0.7037\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7624 - accuracy: 0.7803 - val_loss: 0.9922 - val_accuracy: 0.7098\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7579 - accuracy: 0.7817 - val_loss: 1.0125 - val_accuracy: 0.6976\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7543 - accuracy: 0.7820 - val_loss: 0.9926 - val_accuracy: 0.7069\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7481 - accuracy: 0.7839 - val_loss: 0.9898 - val_accuracy: 0.7121\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7456 - accuracy: 0.7844 - val_loss: 0.9801 - val_accuracy: 0.7089\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7366 - accuracy: 0.7869 - val_loss: 0.9874 - val_accuracy: 0.7119\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7323 - accuracy: 0.7882 - val_loss: 0.9717 - val_accuracy: 0.7110\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7276 - accuracy: 0.7895 - val_loss: 0.9655 - val_accuracy: 0.7148\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7220 - accuracy: 0.7906 - val_loss: 0.9847 - val_accuracy: 0.7079\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7175 - accuracy: 0.7924 - val_loss: 0.9762 - val_accuracy: 0.7134\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7146 - accuracy: 0.7911 - val_loss: 0.9653 - val_accuracy: 0.7134\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7086 - accuracy: 0.7933 - val_loss: 0.9729 - val_accuracy: 0.7118\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.7077 - accuracy: 0.7929 - val_loss: 0.9548 - val_accuracy: 0.7165\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.7013 - accuracy: 0.7953 - val_loss: 0.9525 - val_accuracy: 0.7192\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6964 - accuracy: 0.7962 - val_loss: 0.9481 - val_accuracy: 0.7206\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6940 - accuracy: 0.7962 - val_loss: 0.9493 - val_accuracy: 0.7158\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6893 - accuracy: 0.7981 - val_loss: 0.9526 - val_accuracy: 0.7131\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6846 - accuracy: 0.7977 - val_loss: 0.9522 - val_accuracy: 0.7169\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6810 - accuracy: 0.7996 - val_loss: 0.9414 - val_accuracy: 0.7261\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6782 - accuracy: 0.8002 - val_loss: 0.9425 - val_accuracy: 0.7198\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6724 - accuracy: 0.8013 - val_loss: 0.9387 - val_accuracy: 0.7218\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6714 - accuracy: 0.8014 - val_loss: 0.9341 - val_accuracy: 0.7219\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6648 - accuracy: 0.8038 - val_loss: 0.9447 - val_accuracy: 0.7189\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6637 - accuracy: 0.8056 - val_loss: 0.9519 - val_accuracy: 0.7156\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.6585 - accuracy: 0.8044 - val_loss: 0.9419 - val_accuracy: 0.7194\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6546 - accuracy: 0.8057 - val_loss: 0.9433 - val_accuracy: 0.7173\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6522 - accuracy: 0.8080 - val_loss: 0.9382 - val_accuracy: 0.7203\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6474 - accuracy: 0.8094 - val_loss: 0.9362 - val_accuracy: 0.7219\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6433 - accuracy: 0.8104 - val_loss: 0.9290 - val_accuracy: 0.7260\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6397 - accuracy: 0.8106 - val_loss: 0.9324 - val_accuracy: 0.7268\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6378 - accuracy: 0.8114 - val_loss: 0.9267 - val_accuracy: 0.7256\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6336 - accuracy: 0.8124 - val_loss: 0.9598 - val_accuracy: 0.7163\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6322 - accuracy: 0.8130 - val_loss: 0.9288 - val_accuracy: 0.7266\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6272 - accuracy: 0.8146 - val_loss: 0.9322 - val_accuracy: 0.7206\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6214 - accuracy: 0.8170 - val_loss: 0.9392 - val_accuracy: 0.7247\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6214 - accuracy: 0.8163 - val_loss: 0.9352 - val_accuracy: 0.7250\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6184 - accuracy: 0.8172 - val_loss: 0.9275 - val_accuracy: 0.7321\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6141 - accuracy: 0.8190 - val_loss: 0.9285 - val_accuracy: 0.7313\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6100 - accuracy: 0.8195 - val_loss: 0.9233 - val_accuracy: 0.7303\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.6084 - accuracy: 0.8209 - val_loss: 0.9337 - val_accuracy: 0.7289\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.6041 - accuracy: 0.8223 - val_loss: 0.9185 - val_accuracy: 0.7300\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.5998 - accuracy: 0.8225 - val_loss: 0.9341 - val_accuracy: 0.7229\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.5978 - accuracy: 0.8235 - val_loss: 0.9374 - val_accuracy: 0.7284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCzu6qk70FlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppivXYwF0PC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFJRvGN80X3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a29869d6-eb73-4df2-fa34-2fbd1b34c49a"
      },
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Vete.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Vete.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Vete.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Vete.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Vente.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: ¡Ve elo!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Vete.\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: ¿Quién anor?\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Despara!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Despara!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: ¡Despara!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Vete!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Vete!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: ¡Vete!\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: ¡Dete alo!\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Satente.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Vete a!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Vete a!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: ¡Vete a!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: ¡Desesta!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Allante alo.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Vente.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Vente.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: ¡Lorado!\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Corrí.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Corrí.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Es trerda.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: ¡Prado!\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: ¡Para!\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Abrala a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Menten ararra.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡De pira!\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: ¡De pira!\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Ayada.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Antrade.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: ¡Lo te alo!\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: ¿Qué porro?\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: ¿Qué porro?\n",
            "\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: Mente ciente.\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Menten astrada.\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Ayrada esto.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Me cuerda.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: Me carrió.\n",
            "\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Lo vira.\n",
            "\n",
            "-\n",
            "Input sentence: I lied.\n",
            "Decoded sentence: Mentente.\n",
            "\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: Ve arí.\n",
            "\n",
            "-\n",
            "Input sentence: I quit.\n",
            "Decoded sentence: Mentre.\n",
            "\n",
            "-\n",
            "Input sentence: I quit.\n",
            "Decoded sentence: Mentre.\n",
            "\n",
            "-\n",
            "Input sentence: I work.\n",
            "Decoded sentence: Estrada.\n",
            "\n",
            "-\n",
            "Input sentence: I'm 19.\n",
            "Decoded sentence: Estoy alo.\n",
            "\n",
            "-\n",
            "Input sentence: I'm up.\n",
            "Decoded sentence: Estoy lorada.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Mintente en arira.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Mintente en arira.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Mintente en arira.\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: ¡De pirra!\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: ¿Pien iro?\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: ¿Pien iro?\n",
            "\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: Alala asto.\n",
            "\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: Alala asto.\n",
            "\n",
            "-\n",
            "Input sentence: Try it.\n",
            "Decoded sentence: Pruente alo.\n",
            "\n",
            "-\n",
            "Input sentence: We try.\n",
            "Decoded sentence: Pruén astora.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Minte alo.\n",
            "\n",
            "-\n",
            "Input sentence: Why me?\n",
            "Decoded sentence: ¿Quién an carado?\n",
            "\n",
            "-\n",
            "Input sentence: Ask Tom.\n",
            "Decoded sentence: Ayude a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Awesome!\n",
            "Decoded sentence: ¡Desperra!\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Séntate carra.\n",
            "\n",
            "-\n",
            "Input sentence: Be cool.\n",
            "Decoded sentence: Sénta carri.\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Sé antrente.\n",
            "\n",
            "-\n",
            "Input sentence: Be kind.\n",
            "Decoded sentence: Sén antre.\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Sénta cire.\n",
            "\n",
            "-\n",
            "Input sentence: Beat it.\n",
            "Decoded sentence: Séla asto.\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Allama a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Allama a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Allama a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: ¡Llamame a Tomásto.\n",
            "\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: Vente a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: Vente a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: Vente a Tom.\n",
            "\n",
            "-\n",
            "Input sentence: Come on!\n",
            "Decoded sentence: ¡Vete alo!\n",
            "\n",
            "-\n",
            "Input sentence: Come on.\n",
            "Decoded sentence: Vente aquí.\n",
            "\n",
            "-\n",
            "Input sentence: Come on.\n",
            "Decoded sentence: Vente aquí.\n",
            "\n",
            "-\n",
            "Input sentence: Drop it!\n",
            "Decoded sentence: ¡De prirdo!\n",
            "\n",
            "-\n",
            "Input sentence: Get Tom.\n",
            "Decoded sentence: Ayada a Tomás.\n",
            "\n",
            "-\n",
            "Input sentence: Get out!\n",
            "Decoded sentence: ¡La te alo!\n",
            "\n",
            "-\n",
            "Input sentence: Get out.\n",
            "Decoded sentence: Alata alo.\n",
            "\n",
            "-\n",
            "Input sentence: Get out.\n",
            "Decoded sentence: Alata alo.\n",
            "\n",
            "-\n",
            "Input sentence: Get out.\n",
            "Decoded sentence: Alata alo.\n",
            "\n",
            "-\n",
            "Input sentence: Get out.\n",
            "Decoded sentence: Alata alo.\n",
            "\n",
            "-\n",
            "Input sentence: Get out.\n",
            "Decoded sentence: Alata alo.\n",
            "\n",
            "-\n",
            "Input sentence: Go away!\n",
            "Decoded sentence: ¡La te a aquí!\n",
            "\n",
            "-\n",
            "Input sentence: Go away!\n",
            "Decoded sentence: ¡La te a aquí!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}